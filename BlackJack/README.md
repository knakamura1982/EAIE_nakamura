## 基本的な設計思想
- ディーラープログラムとプレイヤープログラムが分かれており，ソケット通信をしながらゲームを進めます．
  - 様々な戦略のプレイヤーが同一のディーラーを相手に戦っている，ような雰囲気を出すための設計です．
- ディーラーにしか把握できない（はずの）情報は全てディーラープログラム側（dealer.py）に記載されています．
  - ですので，config.py や classes.py に記載の情報はプレイヤープログラム側から参照してOKです．
  - 逆に dealer.py に記載の情報はプレイヤープログラム側からは参照しない，というルールです．
- ディーラープログラムを相手に人間がプレイすることも可能です．

## 実行手順
- 前提として，ターミナルが複数必要になります．
- まず，一方のターミナルで dealer.py を実行します
- dealer.py が接続待ち状態になったら，もう一方のターミナルでプレイヤープログラムを何か一つ実行します．
- プレイヤープログラムが終了しても，dealer.py は終了せず接続待ち状態に入りますので，  
以降はプレイヤープログラムを実行するだけでOKです．
- dealer.py を終了したい場合は Ctrl+C で止めて下さい．

## dealer.py

## human_player.py

## ai_player_rand.py

## ai_player_NN.py

## ai_player_Q.py

## log_selector.py

プレイヤープログラム実行時に出力されたログファイルから「都合が良い」行のみを抽出するプログラム．  
特定条件下のログのみ（例えば勝った時のログのみ，など）を用いて  
ニューラルネットワークを学習したい場合に使用する想定で用意しました．
なお，何を以て「都合が良い」とするかはプレイヤーAIの実装方針に沿って各自で策定して頂き，  
その内容に応じて16行目の内容をご変更ください（13～15行目に記載のコメントも参照）．  

**コマンド**
```
python log_selector.py --in_file play_log.csv --out_file selected_log.csv
```
**オプション**
- in_file
  - プレイヤープログラムから出力された生のログファイル
  - 指定しなかった場合，デフォルト値として play_log.csv がセットされる
- out_file
  - 抽出結果の保存先ファイル
  - 指定しなかった場合，デフォルト値として selected_log.csv がセットされる

## NN_train.py

## QTable_checker.py

## BJNet_models

NN_train.py による学習結果の保存先として使用する想定のフォルダ．  
動作テスト時に作成したファイルが model.pth という名前で残っているが，決して良いモデルではない

## imgs

トランプカードの図柄画像が収められています（human_player.py でのみ使用）．  
なお，素材は下記サイトからお借りしました．  
https://chicodeza.com/freeitems/torannpu-illust.html

## その他

以下のソースファイルは実行対象ではありません．
- **NN_structure.py**
  - ai_player_NN.py で使用するニューラルネットワークの構造が記載されているファイル．
- **classes.py**
  - カードの配布とシャッフル，手札の管理，ディーラーとプレイヤーの通信処理など，  
  雑多な処理を担当するクラス群が記載されているファイル．
- **config.py**
  - 使用するカードデッキの数，カードシャッフルの頻度，ソケット通信のポート番号，  
  といった各種設定値が記載されているファイル．
